---
title: "Exploratorio"
author: "Esteban Rucán"
date: "31-10-2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, fig.align = 'center')
require(tidyverse)
require(roperators)
```

```{r FUNCIONES}
auto_drop1 <- function(data_frame, v_respuesta, v_explicativas, alpha) {
    formula <- as.formula(
            paste(v_respuesta, paste(v_explicativas, collapse = "+"),
            sep = " ~ "))

    full_lin_mod <- lm(formula = formula, data = data_frame)
    detencion <- FALSE

    while(detencion == FALSE) {

        drop_1 <- drop1(full_lin_mod, test = "Chisq")
        maximo <- drop_1$`Pr(>Chi)`[!is.na(drop_1$`Pr(>Chi)`)] %>% max()
        indice <- which(drop_1$`Pr(>Chi)`== maximo) - 1

        if(maximo >= alpha) {

            v_explicativas <- v_explicativas[-indice]
            actualizacion <- as.formula(
                paste("~ ", paste(v_explicativas, collapse = "+"), sep = ""))
            full_lin_mod <- update(full_lin_mod, actualizacion)

        } else {
            detencion <- TRUE
        }
    }

    return(full_lin_mod)
}

auto_add1 <- function(data_frame, v_respuesta, v_explicativas, alpha) {
    formula <- as.formula(paste(v_respuesta, "1", sep = " ~ "))
    scope <- as.formula(
        paste("~ ", paste(v_explicativas, collapse = "+"), sep = ""))
    null_lin_mod <- lm(formula = formula, data = data_frame)
    detencion <- FALSE
    variables <- c()

    while(detencion == FALSE) {

        add_1 <- add1(null_lin_mod, scope = scope, test = "Chisq")
        minimo <- add_1$`Pr(>Chi)`[!is.na(add_1$`Pr(>Chi)`)] %>% min()
        indice <- which(add_1$`Pr(>Chi)`== minimo) - 1

        if(minimo <= alpha) {
            variables <- c(variables, v_explicativas[indice])
            v_explicativas <- v_explicativas[-indice]
            actualizacion <- as.formula(
                paste("~ ", paste(variables, collapse = "+"), sep = ""))
            null_lin_mod <- update(null_lin_mod, actualizacion)

        } else {
            detencion <- TRUE
        }
    }

    return(null_lin_mod)
}

supuestos <- function(modelo) {
    dw <- modelo %>% lmtest::dwtest()
    independencia <- dw$statistic
    
    ks <- modelo %>% rstandard() %>% ks.test("pnorm") 
    normalidad <- ks$p.value
    
    bp <- modelo %>% lmtest::bptest()
    homocedasticidad <- bp$p.value 
    
    return(c(independencia, normalidad, homocedasticidad))
}

auto_vif <- function(data_frame, v_respuesta, v_explicativas, criterio = 10) {
    
    data_frame <- data
    v_respuesta <- "critical_temp"
    v_explicativas <- variables
    formula <- as.formula(
            paste(v_respuesta, paste(v_explicativas, collapse = "+"),
            sep = " ~ "))

    full_lin_mod <- lm(formula = formula, data = data_frame)
    detencion <- FALSE
    contador <- 0

    while(detencion == FALSE) {

        vifs <- car::vif(full_lin_mod)
        maximo <- vifs %>% max()
        indice <- which(vifs == maximo)

        if(maximo >= criterio) {

            v_explicativas <- v_explicativas[-indice]
            actualizacion <- as.formula(
                paste("~ ", paste(v_explicativas, collapse = "+"), sep = ""))
            full_lin_mod <- update(full_lin_mod, actualizacion)
            contador %+=% 1

        } else {
            detencion <- TRUE
        }
    }
    
    full_lin_mod <- step(full_lin_mod, direction = "forward", scope = full_lin_mod$terms, trace = 0)
    full_lin_mod$variables_borradas <- contador

    return(full_lin_mod)
}

eliminar_multicolinealidad <- function(modelo, criterio) {
    v_explicativas <- names(modelo$coefficients)[-1]
    
    detencion <- FALSE
    contador <- 0
    
    while(detencion == FALSE) {
        vifs <- car::vif(modelo)
        maximo <- vifs %>% max()
        indice <- which(vifs == maximo)

        if(maximo >= criterio) {

            v_explicativas <- v_explicativas[-indice]
            actualizacion <- as.formula(
                paste("~ ", paste(v_explicativas, collapse = "+"), sep = ""))
            modelo <- update(modelo, actualizacion, data = data)
            contador %+=% 1

        } else {
            detencion <- TRUE
        }
    }
    
    modelo <- step(modelo, direction = "forward", scope = modelo$terms, trace = 0)
    
    modelo$variables_borradas <- contador
    
    return(modelo)
        
}

aic <- function(modelo) {
    modelo <- step(modelo, direction = "forward", scope = modelo$terms, trace = 0)
    return(modelo$anova$AIC %>% min())
}

bic <- function(modelo) {
    modelo <- step(modelo, direction = "forward", 
                   k = modelo$model %>% nrow() %>% log(), 
                   scope = modelo$terms, trace = 0)
    return(modelo$anova$AIC %>% min()) 
}

```



```{r BASE}
data <- rio::import("datos/clean_db.csv")[2:35]
data$number_of_elements <- NULL
variables <- names(data)[1:32][-25]
formula <- "critical_temp ~ " %+% paste(variables, collapse = "+") %>% as.formula()
```

```{r MODELOS}
full_mod <- lm(formula = formula, data = data)
null_mod <- lm(formula = critical_temp ~ 1, data = data)

# bw
backward <- step(full_mod, direction = "backward", trace = 0) %>%
    eliminar_multicolinealidad(criterio = 10)
aic_backward <- backward %>% aic()
bic_backward <- backward %>% bic()
variables_backward <- backward %>% coefficients()
supuestos_backward <- backward %>% supuestos()
r_squared_backward <- summary(backward)$r.squared
v_borradas_backward <- backward$variables_borradas

# 

# fw
forward <- step(full_mod, direction = "forward", scope = formula, trace = 0) %>%
    eliminar_multicolinealidad(criterio = 10)
aic_forward <- forward %>% aic()
bic_forward <- forward %>% bic()
variables_forward <- forward %>% coefficients()
supuestos_forward <- forward %>% supuestos()
r_squared_forward <- summary(forward)$r.squared
v_borradas_forward <- forward$variables_borradas

# stepwise
stepwise <- step(full_mod, direction = "both", trace = 0) %>%
    eliminar_multicolinealidad(criterio = 10)
aic_stepwise <- stepwise %>% aic()
bic_stepwise <- stepwise %>% bic()
variables_stepwise <- stepwise %>% coefficients()
supuestos_stepwise <- stepwise %>% supuestos()
r_squared_stepwise <- summary(stepwise)$r.squared
v_borradas_stepwise <- stepwise$variables_borradas

# drop1
drop1 <- auto_drop1(data, "critical_temp", variables, 0.05) %>%
    eliminar_multicolinealidad(criterio = 10)
aic_drop1 <- drop1 %>% aic()
bic_drop1 <- drop1 %>% bic()
variables_drop1 <- drop1 %>% coefficients()
supuestos_drop1 <- drop1 %>% supuestos()
r_squared_drop1 <- summary(drop1)$r.squared
v_borradas_drop1 <- drop1$variables_borradas

# add1
add1 <- auto_add1(data, "critical_temp", variables, 0.05) %>%
    eliminar_multicolinealidad(criterio = 10)
aic_add1 <- add1 %>% aic()
bic_add1 <- add1 %>% bic()
variables_add1 <- add1 %>% coefficients()
supuestos_add1 <- add1 %>% supuestos()
r_squared_add1 <- summary(add1)$r.squared
v_borradas_add1 <- add1$variables_borradas

# Vif
mod_vif <- auto_vif(data, "critical_temp", variables, 10) %>%
    eliminar_multicolinealidad(criterio = 10)
aic_vif <- mod_vif %>% aic()
bic_vif <- mod_vif %>% bic()
variables_vif <- mod_vif %>% coefficients()
supuestos_vif <- mod_vif %>% supuestos()
r_squared_vif <- summary(mod_vif)$r.squared

coef(backward) %>% sort() %>% summary()

```


```{r BACKWARD POINTS}
# OUTLIERS

residuos_estandarizados <- mod_weighted_vif %>% rstandard()
valores_ajustados <- mod_weighted_vif %>% fitted.values()

ggplot(mapping = aes(valores_ajustados, residuos_estandarizados)) +
    theme_bw() +
    labs(title = "Outliers",
         x = "Valores Ajustados",
         y = "Residuos Estandarizados") +
    theme(plot.title = element_text(hjust = 0.5)) +
    geom_jitter(color = "dodgerblue") +
    geom_hline(yintercept = -2, color = "deepskyblue4", linetype = 2) +
    geom_hline(yintercept = 2, color = "deepskyblue4", linetype = 2) +
    ylim(-6, 6)

outliers <- residuos_estandarizados[residuos_estandarizados > 2 |
                                     residuos_estandarizados < -2]
indices <- outliers %>% names() %>% as.numeric()

data_bw <- data[-indices, ]

full_mod_p <- lm(formula = formula, data = data_bw)
backward_p <- step(full_mod_p, direction = "backward", trace = 0) %>%
    eliminar_multicolinealidad(criterio = 10)
aic_backward_p <- backward_p %>% aic()
bic_backward_p <- backward_p %>% bic()
variables_backward_p <- backward_p %>% coefficients() %>% length()
supuestos_backward_p <- backward_p %>% supuestos()
r_squared_backward_p <- summary(backward_p)$r.squared
v_borradas_backward_p <- backward_p$variables_borradas

# PLOT
residuos_estandarizados <- backward_p %>% rstandard()
valores_ajustados <- backward_p %>% fitted.values()

ggplot(mapping = aes(valores_ajustados, residuos_estandarizados)) +
    theme_bw() +
    labs(title = "Outliers",
         x = "Valores Ajustados",
         y = "Residuos Estandarizados") +
    theme(plot.title = element_text(hjust = 0.5)) +
    geom_jitter(color = "dodgerblue") +
    geom_hline(yintercept = -2, color = "deepskyblue4", linetype = 2) +
    geom_hline(yintercept = 2, color = "deepskyblue4", linetype = 2) +
    ylim(-6, 6)


# PALANCA
hat_values <- mod_weighted_vif %>% hatvalues()
parametros <- mod_weighted_vif %>% coefficients() %>% length()

observaciones <- nrow(data)

criterio_1 <- 2 * (parametros + 1) / observaciones
criterio_2 <- 2 * parametros / observaciones

ggplot(mapping = aes(hat_values, residuos_estandarizados)) +
    theme_bw() +
    labs(title = "Puntos Extremos",
         x = "Hat Values",
         y = "Residuos Estandarizados") +
    theme(plot.title = element_text(hjust = 0.5)) +
    geom_point(color = "dodgerblue") +
    geom_vline(xintercept = criterio_1, color = "deepskyblue4", linetype = 2) +
    geom_vline(xintercept = criterio_2, color = "brown3", linetype = 2)
puntos_extremos_criterio_1 <- hat_values[hat_values > criterio_1]

# INFLUENCIA

dffits <- dffits(mod_weighted_vif)
abs_dffits <- abs(dffits)
indices <- seq_along(abs_dffits)
criterio <- 2 * sqrt(parametros / observaciones)
# Porque hay muchas observaciones

ggplot(mapping = aes(indices, abs_dffits)) +
    theme_bw() +
    labs(title = "Puntos de Influencia",
         x = "Índice",
         y = "|DFFITS|") +
    theme(plot.title = element_text(hjust = 0.5)) +
    geom_point(color = "dodgerblue") +
    geom_hline(yintercept = criterio, color = "deepskyblue4", linetype = 2) +
    ylim(0,.5)

puntos_de_influencia <- abs_dffits[abs_dffits > criterio] %>% names() %>% as.numeric()

data_bw <- data[-puntos_de_influencia, ]

full_mod_p <- lm(formula = formula, data = data_bw)
backward_p <- step(full_mod_p, direction = "backward", trace = 0) %>%
    eliminar_multicolinealidad(criterio = 10)
aic_backward_p <- backward_p %>% aic()
bic_backward_p <- backward_p %>% bic()
variables_backward_p <- backward_p %>% coefficients() %>% length()
supuestos_backward_p <- backward_p %>% supuestos()
r_squared_backward_p <- summary(backward_p)$r.squared
v_borradas_backward_p <- backward_p$variables_borradas 

backward_p %>% summary()

```



```{r BACKWARD WLS}

ggplot(mapping = aes(backward$fitted.values, abs(backward$residuals))) +
    theme_bw() +
    labs(title = "Residuos Estandarizados vs Valores ajustados",
         x = "Valores Ajustados",
         y = "|Residuos Estandarizados|") +
    theme(plot.title = element_text(hjust = 0.5)) +
    geom_jitter(color = "dodgerblue") +
    geom_hline(yintercept = 0, size = 0.2) +
    geom_smooth(color = "deepskyblue4", method = "loess",
                formula = y ~ x, se = FALSE) +
    xlim(0, 150) +
    ylim(0,500)

abs_res <- abs(backward$residuals)
terminos <- as.character(backward$terms)
form <- as.formula(paste("abs_res ~", terminos[3], sep = ""))
residuos_abs_mod <- lm(form, data = data)

summary(residuos_abs_mod)

mod_weights <- 1 / 7.68 ^ (residuos_abs_mod$fitted.values)

mod_weighted <- lm(formula = formula(backward), data = data, weights = mod_weights) %>% eliminar_multicolinealidad(criterio = 10)

summary(mod_weighted)

ggplot(mapping = aes(mod_weighted$fitted.values, abs(mod_weighted$residuals))) +
    theme_bw() +
    labs(title = "Residuos Estandarizados vs Valores ajustados",
         x = "Valores Ajustados",
         y = "|Residuos Estandarizados|") +
    theme(plot.title = element_text(hjust = 0.5)) +
    geom_jitter(color = "dodgerblue") +
    geom_hline(yintercept = 0, size = 0.2) +
    geom_smooth(color = "deepskyblue4", method = "loess",
                formula = y ~ x, se = FALSE) +
    xlim(0, 150) +
    ylim(0,500)



final <- cbind(data$critical_temp, mod_weighted$fitted.values)
boxplot(final)
plot(final)

plot(density(final[,1]))
lines(density(final[,2]))

qqplot(sort(final[,1]), sort(final[,2]))

actual <- data$critical_temp 
preds <- mod_weighted$fitted.values
rss <- sum((preds - actual) ^ 2)
tss <- sum((actual - mean(actual)) ^ 2)
rsq <- 1 - rss/tss
rsq

boxplot(data$critical_temp)

plot(data$critical_temp ~ mod_weighted$fitted.values)
abline(0,1)
```



```{r RIDGE REGRESSION}
data_ridge <- data
data_ridge$range_Valence <- NULL
x_vars <- model.matrix(critical_temp~. , data_ridge)[,-1]
y_var <- data_ridge$critical_temp
lambda_seq <- 10^seq(-2, 5, by = 0.001)

#set.seed(86)
#train = sample(1:nrow(x_vars), 0.9 * nrow(x_vars))
#x_test = (-train)
#y_test = y_var[x_test]

cv_output <- glmnet::cv.glmnet(x_vars, y_var,
                       alpha = 0, lambda = lambda_seq, 
                       nfolds = 10)
 
# identifying best lambda
best_lam <- cv_output$lambda.min

# Rebuilding the model with best lamda value identified
ridge_best <- glmnet::glmnet(x_vars, y_var, alpha = 0, lambda = best_lam)
pred <- predict(ridge_best, s = best_lam, newx = x_vars)

final <- cbind(y_var, pred)

actual <- y_var
preds <- pred
rss <- sum((preds - actual) ^ 2)
tss <- sum((actual - mean(actual)) ^ 2)
rsq <- 1 - rss/tss
rsq




```


```{r LASSO REGRESSION}
data_ridge <- data
data_ridge$range_Valence <- NULL
x_vars <- model.matrix(critical_temp~. , data_ridge)[,-1]
y_var <- data_ridge$critical_temp
lambda_seq <- 10^seq(-2, 10, by = 0.1)

set.seed(86)
train = sample(1:nrow(x_vars), 0.5 * nrow(x_vars))
x_test = (-train)
y_test = y_var[x_test]

cv_output <- glmnet::cv.glmnet(x_vars[train,], y_var[train],
                       alpha = 1, lambda = lambda_seq, 
                       nfolds = 10)


 
# identifying best lambda
best_lam <- cv_output$lambda.min

# Rebuilding the model with best lamda value identified
lasso_best <- glmnet::glmnet(x_vars[train,], y_var[train], alpha = 1, lambda = best_lam)
pred <- predict(lasso_best, s = best_lam, newx = x_vars[x_test,])

final <- cbind(y_var[-train], pred)



actual <- y_var[-train]
preds <- pred
rss <- sum((preds - actual) ^ 2)
tss <- sum((actual - mean(actual)) ^ 2)
rsq <- 1 - rss/tss

plot(actual ~ preds)
```

```{r results="hide"}
data_av_1 <- data
data_av_1$number_of_elements <- NULL

lin_mods_bw <- list()
#lin_mods_fw <- list()
#lin_mods_bf <- list()

supuestos_mods_bw <- list()
#supuestos_mods_fw <- list()
#supuestos_mods_bf <- list()

vr <- c()
fitted_values_bw <- c()
#fitted_values_fw <- c()
#fitted_values_bf <- c()

av1_bw_aic <- vector(mode = "numeric", length = 7)
#av1_fw_aic <- vector(mode = "numeric", length = 7)
#av1_bf_aic <- vector(mode = "numeric", length = 7)

av1_bw_bic <- vector(mode = "numeric", length = 7)
#av1_fw_bic <- vector(mode = "numeric", length = 7)
#av1_bf_bic <- vector(mode = "numeric", length = 7)

for(i in 0:6){
    new_data <- data_av_1 %>% 
        filter(range_Valence == i)
    new_data$range_Valence <- NULL
    
    variables_var_minima <- caret::nearZeroVar(new_data, names = TRUE)
    
    for(variable in variables_var_minima){
        new_data[[variable]] <- NULL
    }
    
    full_lin_mod_i <- lm(critical_temp ~ ., data = new_data)
    #null_lin_mod_i <- lm(critical_temp ~ 1, data = new_data)
    
    if(summary(full_lin_mod_i)$r.squared != 1){
        lin_mods_bw[[paste(i)]] <- step(full_lin_mod_i, direction = "backward", trace = 0) 
        #lin_mods_fw[[paste(i)]] <- step(null_lin_mod_i, direction = "forward", scope = formula(full_lin_mod_i), trace = 0) 
        #lin_mods_bf[[paste(i)]] <- step(full_lin_mod_i, direction = "both", trace = 0)
        
        av1_bw_aic[i + 1] <- lin_mods_bw[[paste(i)]] %>% aic()
        #av1_fw_aic[i + 1] <- lin_mods_fw[[paste(i)]] %>% aic()
        #av1_bf_aic[i + 1] <- lin_mods_bf[[paste(i)]] %>% aic()
        
        av1_bw_bic[i + 1] <- lin_mods_bw[[paste(i)]] %>% bic()
        #av1_fw_bic[i + 1] <- lin_mods_fw[[paste(i)]] %>% bic()
        #av1_bf_bic[i + 1] <- lin_mods_bf[[paste(i)]] %>% bic()
        
        supuestos_mods_bw[[paste(i)]] <- supuestos(lin_mods_bw[[paste(i)]])
        #supuestos_mods_fw[[paste(i)]] <- supuestos(lin_mods_fw[[paste(i)]])
        #supuestos_mods_bf[[paste(i)]] <- supuestos(lin_mods_bf[[paste(i)]])
    } else {
        lin_mods_bw[[paste(i)]] <- full_lin_mod_i
        #lin_mods_fw[[paste(i)]] <- full_lin_mod_i 
        #lin_mods_bf[[paste(i)]] <- full_lin_mod_i 
        
        av1_bw_aic[i + 1] <- 0
        #av1_fw_aic[i + 1] <- 0
        #av1_bf_aic[i + 1] <- 0
    }
    
    vr <- c(vr, new_data$critical_temp)
    
    fitted_values_bw <- c(fitted_values_bw, lin_mods_bw[[paste(i)]]$fitted.values)
    #fitted_values_fw <- c(fitted_values_fw, lin_mods_fw[[paste(i)]]$fitted.values)
    #fitted_values_bf <- c(fitted_values_bf, lin_mods_bf[[paste(i)]]$fitted.values)
}

correlacion_bw <- cor(vr, fitted_values_bw)
#correlacion_fw <- cor(vr, fitted_values_fw)
#correlacion_bf <- cor(vr, fitted_values_bf)

aic_bw_av_1 <- sum(av1_bw_aic)
#aic_fw_av_1 <- sum(av1_fw_aic)
#aic_bf_av_1 <- sum(av1_bf_aic)

bic_bw_av_1 <- sum(av1_bw_bic)
#bic_fw_av_1 <- sum(av1_fw_bic)
#bic_bf_av_1 <- sum(av1_bf_bic)

r_squared_bw_av_1 <- correlacion_bw ^ 2

```

